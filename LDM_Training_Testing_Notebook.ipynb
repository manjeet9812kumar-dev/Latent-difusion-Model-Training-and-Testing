{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12845063,"sourceType":"datasetVersion","datasetId":8124209}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers\n# !pip install --upgrade --force-reinstall \"tensorflow==2.15.1\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:07:01.851981Z","iopub.execute_input":"2025-08-23T19:07:01.852487Z","iopub.status.idle":"2025-08-23T19:07:05.833761Z","shell.execute_reply.started":"2025-08-23T19:07:01.852466Z","shell.execute_reply":"2025-08-23T19:07:05.833004Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom diffusers import AutoencoderKL\nimport os, math, numpy as np, pandas as pd, tensorflow as tf\nfrom tensorflow import keras\nfrom keras import layers\nfrom keras.models import Model\nfrom matplotlib import pyplot as plt\nfrom tensorflow.keras import mixed_precision\n# mixed_precision.set_global_policy(\"mixed_float16\")  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:07:05.835095Z","iopub.execute_input":"2025-08-23T19:07:05.835323Z","iopub.status.idle":"2025-08-23T19:07:33.728627Z","shell.execute_reply.started":"2025-08-23T19:07:05.835302Z","shell.execute_reply":"2025-08-23T19:07:33.727788Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"vae = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-ema\")\n\ntorch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nvae.to(torch_device)\nvae.eval()\nprint(\"VAE device:\", torch_device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:07:33.729414Z","iopub.execute_input":"2025-08-23T19:07:33.730005Z","iopub.status.idle":"2025-08-23T19:07:36.237794Z","shell.execute_reply.started":"2025-08-23T19:07:33.729982Z","shell.execute_reply":"2025-08-23T19:07:36.237138Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntrain_label_embeddings =  np.load(\"/kaggle/input/text-to-image-dataset/text_embeddings.npy\")\nlatent_train_data = np.load(\"/kaggle/input/text-to-image-dataset/image_latents.npy\")\n \n\nprint(\"training dataset ready\")\nprint(\"latent_train_data shape:\", latent_train_data.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:07:36.239234Z","iopub.execute_input":"2025-08-23T19:07:36.239476Z","iopub.status.idle":"2025-08-23T19:07:45.475011Z","shell.execute_reply.started":"2025-08-23T19:07:36.239457Z","shell.execute_reply":"2025-08-23T19:07:45.474203Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def imshow(img):\n    def norm_0_1(img):\n        return (img + 1) / 2  # from [-1,1] to [0,1]\n    if img.shape[-1] == 1:\n        img = img.reshape(img.shape[0], img.shape[1])\n    img = np.clip(img, -1, 1)\n    plt.imshow(norm_0_1(img))\n\ndef plot_images(imgs, size=8, nrows=8, save_name=None):\n    plt.rcParams[\"figure.figsize\"] = (size, size)\n    for i in range(len(imgs)):\n        ax = plt.subplot(nrows, nrows, i + 1)\n        imshow(imgs[i])\n        plt.gray()\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n    if save_name:\n        plt.savefig(f\"{save_name}.png\", dpi=200)\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:07:45.475954Z","iopub.execute_input":"2025-08-23T19:07:45.476215Z","iopub.status.idle":"2025-08-23T19:07:45.482635Z","shell.execute_reply.started":"2025-08-23T19:07:45.476190Z","shell.execute_reply":"2025-08-23T19:07:45.481922Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def decode_latents(latent_arr, std_latent=1.0, batch_size=32):\n\n    decoded_imgs = []\n    N = latent_arr.shape[0]\n    with torch.no_grad():\n        for start in range(0, N, batch_size):\n            end = min(start + batch_size, N)\n            # NHWC -> NCHW, float32 tensor on the VAE device\n            encoded = torch.from_numpy(latent_arr[start:end] * float(std_latent)).permute(0, 3, 1, 2).to(torch_device, dtype=torch.float32)\n            # Decode with the PyTorch VAE\n            decoded = vae.decode(encoded).sample  # (N, 3, H_dec, W_dec), in [-1, 1]\n            # NCHW -> NHWC, move to CPU numpy\n            decoded_imgs.append(decoded.permute(0, 2, 3, 1).cpu().numpy())\n\n    return np.concatenate(decoded_imgs, axis=0)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:07:45.483403Z","iopub.execute_input":"2025-08-23T19:07:45.483670Z","iopub.status.idle":"2025-08-23T19:07:45.504999Z","shell.execute_reply.started":"2025-08-23T19:07:45.483652Z","shell.execute_reply":"2025-08-23T19:07:45.504285Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_size = 16\nnum_channels = 4\nepochs = 130\nclass_guidance = 4\n\nblock_depth = 3\nemb_size = 512\nembedding_dims = 32\n\nbatch_size = 256\nnum_imgs = 36\n\nvalidation_num = 300\ntrain_size = 100000\nlearning_rate = 3e-4\n\nMODEL_NAME = \"text_to_image\"\nhome_dir = MODEL_NAME\nos.makedirs(home_dir, exist_ok=True)\nmodel_path = os.path.join(home_dir, MODEL_NAME + \".h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:07:45.505830Z","iopub.execute_input":"2025-08-23T19:07:45.506111Z","iopub.status.idle":"2025-08-23T19:07:45.519884Z","shell.execute_reply.started":"2025-08-23T19:07:45.506093Z","shell.execute_reply":"2025-08-23T19:07:45.519118Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def attention(qkv):\n    q, k, v = qkv\n    vector = tf.matmul(k, q, transpose_b=True)\n    score = tf.nn.softmax(vector)\n    o = tf.matmul(score, v)\n    return o\n\ndef spatial_attention(img):\n    filters = img.shape[3]\n    orig_shape = (img.shape[1], img.shape[2], img.shape[3])\n    img = layers.BatchNormalization()(img)\n\n    q = layers.Conv2D(filters // 8, 1, padding=\"same\")(img)\n    k = layers.Conv2D(filters // 8, 1, padding=\"same\")(img)\n    v = layers.Conv2D(filters, 1, padding=\"same\")(img)\n\n    k = layers.Reshape((k.shape[1] * k.shape[2], k.shape[3]))(k)\n    q = layers.Reshape((q.shape[1] * q.shape[2], q.shape[3]))(q)\n    v = layers.Reshape((v.shape[1] * v.shape[2], v.shape[3]))(v)\n\n    img = layers.Lambda(attention)([q, k, v])\n    img = layers.Reshape(orig_shape)(img)\n\n    img = layers.Conv2D(filters, 1, padding=\"same\")(img)\n    img = layers.BatchNormalization()(img)\n    return img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:07:45.520645Z","iopub.execute_input":"2025-08-23T19:07:45.521257Z","iopub.status.idle":"2025-08-23T19:07:45.534111Z","shell.execute_reply.started":"2025-08-23T19:07:45.521232Z","shell.execute_reply":"2025-08-23T19:07:45.533444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def cross_attention(img, text):\n    filters = img.shape[3]\n    orig_shape = (img.shape[1], img.shape[2], img.shape[3])\n    img = layers.BatchNormalization()(img)\n    text = layers.BatchNormalization()(text)\n\n    q = layers.Conv2D(filters // 8, 1, padding=\"same\")(text)\n    k = layers.Conv2D(filters // 8, 1, padding=\"same\")(img)\n    v = layers.Conv2D(filters, 1, padding=\"same\")(text)\n\n    q = layers.Reshape((q.shape[1] * q.shape[2], q.shape[3]))(q)\n    k = layers.Reshape((k.shape[1] * k.shape[2], k.shape[3]))(k)\n    v = layers.Reshape((v.shape[1] * v.shape[2], v.shape[3]))(v)\n\n    img = layers.Lambda(attention)([q, k, v])\n    img = layers.Reshape(orig_shape)(img)\n\n    img = layers.Conv2D(filters, 1, padding=\"same\")(img)\n    img = layers.BatchNormalization()(img)\n    return img","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:07:45.534753Z","iopub.execute_input":"2025-08-23T19:07:45.534946Z","iopub.status.idle":"2025-08-23T19:07:45.550872Z","shell.execute_reply.started":"2025-08-23T19:07:45.534932Z","shell.execute_reply":"2025-08-23T19:07:45.550282Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def sinusoidal_embedding(x):\n    embedding_min_frequency = 1.0\n    embedding_max_frequency = 1000.0\n    embedding_dims = 32\n    frequencies = tf.exp(\n        tf.linspace(\n            tf.math.log(embedding_min_frequency),\n            tf.math.log(embedding_max_frequency),\n            embedding_dims // 2,\n        )\n    )\n    angular_speeds = 2.0 * math.pi * frequencies\n    embeddings = tf.concat(\n        [tf.sin(angular_speeds * x), tf.cos(angular_speeds * x)], axis=3\n    )\n    return embeddings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:07:45.553509Z","iopub.execute_input":"2025-08-23T19:07:45.553738Z","iopub.status.idle":"2025-08-23T19:07:45.565226Z","shell.execute_reply.started":"2025-08-23T19:07:45.553724Z","shell.execute_reply":"2025-08-23T19:07:45.564591Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def ResidualBlock(channel_num):\n    def apply(x):\n        input_channel = x.shape[3]\n        residual = x if input_channel == channel_num else layers.Conv2D(channel_num, 1)(x)\n        x = layers.BatchNormalization(center=False, scale=False)(x)\n        x = layers.Conv2D(channel_num, 3, padding=\"same\", activation=keras.activations.swish)(x)\n        x = layers.Conv2D(channel_num, 3, padding=\"same\")(x)\n        x = layers.Add()([x, residual])\n        return x\n    return apply","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:07:45.565899Z","iopub.execute_input":"2025-08-23T19:07:45.566137Z","iopub.status.idle":"2025-08-23T19:07:45.582696Z","shell.execute_reply.started":"2025-08-23T19:07:45.566121Z","shell.execute_reply":"2025-08-23T19:07:45.582091Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def DownBlock(channel_num, block_depth, use_self_attention=True):\n    def apply(x):\n        x, skip, emb_and_noise = x\n        for _ in range(block_depth):\n            x = ResidualBlock(channel_num)(x)\n            if use_self_attention:\n                att = spatial_attention(x)\n                x = layers.Add()([x, att])\n                cross_att = cross_attention(x, emb_and_noise)\n                x = layers.Add()([x, cross_att])\n            skip.append(x)\n        x = layers.AveragePooling2D(pool_size=2)(x)\n        return x\n    return apply","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:07:45.583400Z","iopub.execute_input":"2025-08-23T19:07:45.583563Z","iopub.status.idle":"2025-08-23T19:07:45.597698Z","shell.execute_reply.started":"2025-08-23T19:07:45.583550Z","shell.execute_reply":"2025-08-23T19:07:45.596880Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def UpBlock(channel_num, block_depth, use_self_attention=True):\n    def apply(x):\n        x, skips, emb_and_noise = x\n        x = layers.UpSampling2D(size=2, interpolation=\"bilinear\")(x)\n        for _ in range(block_depth):\n            x = layers.Concatenate()([x, skips.pop()])\n            x = ResidualBlock(channel_num)(x)\n            if use_self_attention:\n                att = spatial_attention(x)\n                x = layers.Add()([x, att])\n                cross_att = cross_attention(x, emb_and_noise)\n                x = layers.Add()([x, cross_att])\n        return x\n    return apply","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:07:45.598347Z","iopub.execute_input":"2025-08-23T19:07:45.598588Z","iopub.status.idle":"2025-08-23T19:07:45.611820Z","shell.execute_reply.started":"2025-08-23T19:07:45.598547Z","shell.execute_reply":"2025-08-23T19:07:45.611106Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_network(latent_image_size, block_depth=3, emb_size=512, latent_channels=4):\n    noisy_images = keras.Input(shape=(latent_image_size, latent_image_size, latent_channels))\n    x = layers.Conv2D(128, 1)(noisy_images)\n\n    noise_variances = keras.Input(shape=(1, 1, 1))\n    e = layers.Lambda(sinusoidal_embedding, output_shape=(1, 1, 32),name=\"time_embedding\")(noise_variances)\n    e = layers.UpSampling2D(size=(latent_image_size, latent_image_size), interpolation=\"nearest\")(e)\n\n    input_label = layers.Input(shape=(emb_size,))\n    emb_label = layers.Dense(emb_size // 2)(input_label)\n    emb_label = layers.Reshape((1, 1, emb_size // 2))(emb_label)\n    emb_label = layers.UpSampling2D(size=(latent_image_size, latent_image_size), interpolation=\"nearest\")(emb_label)\n\n    emb_and_noise = layers.Concatenate()([e, emb_label])\n    skips_connections = []\n\n    x = DownBlock(128, block_depth, use_self_attention=False)([x, skips_connections, emb_and_noise])\n    emb_and_noise = layers.AveragePooling2D(pool_size=(2, 2))(emb_and_noise)\n\n    x = DownBlock(256, block_depth)([x, skips_connections, emb_and_noise])\n    emb_and_noise = layers.AveragePooling2D(pool_size=(2, 2))(emb_and_noise)\n\n    x = DownBlock(512, block_depth)([x, skips_connections, emb_and_noise])\n    emb_and_noise = layers.AveragePooling2D(pool_size=(2, 2))(emb_and_noise)\n\n    for _ in range(block_depth):\n        x = ResidualBlock(128*5)(x)\n        o = spatial_attention(x)\n        x = layers.Add()([x, o])\n        cross_att = cross_attention(x, emb_and_noise)\n        x = layers.Add()([x, cross_att])\n\n    x = UpBlock(512, block_depth)([x, skips_connections, emb_and_noise])\n    emb_and_noise = layers.UpSampling2D(size=(2, 2), interpolation=\"nearest\")(emb_and_noise)\n\n    x = UpBlock(256, block_depth)([x, skips_connections, emb_and_noise])\n    emb_and_noise = layers.UpSampling2D(size=(2, 2), interpolation=\"nearest\")(emb_and_noise)\n\n    x = UpBlock(128, block_depth)([x, skips_connections, emb_and_noise])\n    emb_and_noise = layers.UpSampling2D(size=(2, 2), interpolation=\"nearest\")(emb_and_noise)\n\n    x = layers.Conv2D(latent_channels, 1, kernel_initializer=\"zeros\")(x)\n    return keras.Model([noisy_images, noise_variances, input_label], x, name=\"unet\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:07:45.612486Z","iopub.execute_input":"2025-08-23T19:07:45.612750Z","iopub.status.idle":"2025-08-23T19:07:45.630427Z","shell.execute_reply.started":"2025-08-23T19:07:45.612729Z","shell.execute_reply":"2025-08-23T19:07:45.629779Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"np.random.seed(100)\nnum_imgs = 25\nrand_image = np.random.normal(0, 1, (num_imgs, image_size, image_size, num_channels))\n\n# with strategy.scope():\n#     unet = get_network(16)\n#     unet.compile(\n#         optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n#         loss=\"mae\",\n#         steps_per_execution=50,   # try 50 or 100\n#     )\n\nunet = get_network(16)\nunet.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mae\")\nprint(\"Number of parameters:\", unet.count_params())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:07:45.631204Z","iopub.execute_input":"2025-08-23T19:07:45.631395Z","iopub.status.idle":"2025-08-23T19:07:49.393084Z","shell.execute_reply.started":"2025-08-23T19:07:45.631381Z","shell.execute_reply":"2025-08-23T19:07:49.392486Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ns = np.arange(10020,10020+5)\nlabels = []\nfor n in ns:\n    for i in range(5):\n        labels.append(train_label_embeddings[n])\nlabels = np.array(labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:07:49.393748Z","iopub.execute_input":"2025-08-23T19:07:49.393960Z","iopub.status.idle":"2025-08-23T19:07:49.398642Z","shell.execute_reply.started":"2025-08-23T19:07:49.393944Z","shell.execute_reply":"2025-08-23T19:07:49.397875Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"std_latent = np.std(latent_train_data)*2.5\nlatent_train_data = np.clip(latent_train_data, -std_latent, std_latent)\nlatent_train_data = latent_train_data/std_latent\nprint(\"std_latent\", std_latent)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:07:49.399549Z","iopub.execute_input":"2025-08-23T19:07:49.399862Z","iopub.status.idle":"2025-08-23T19:07:50.503324Z","shell.execute_reply.started":"2025-08-23T19:07:49.399828Z","shell.execute_reply":"2025-08-23T19:07:50.502546Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def add_noise(array, mu=0, std=1):\n    x = np.abs(np.random.normal(0, std, 2 * len(array)))\n    x = x[x < 3]\n    x = x / 3\n    x = x[:len(array)]\n    noise_levels = x\n    noise_levels = np.sin(noise_levels)\n    signal_levels = np.sqrt(1-np.square(noise_levels))\n    noise_level_reshape = noise_levels[:, None, None, None]\n    signal_level_reshape = signal_levels[:, None, None, None]\n    pure_noise = np.random.normal(0, 1, size=array.shape).astype(\"float32\")\n    noisy_data = array * signal_level_reshape + pure_noise * noise_level_reshape\n    return noisy_data, noise_levels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:07:50.504193Z","iopub.execute_input":"2025-08-23T19:07:50.504478Z","iopub.status.idle":"2025-08-23T19:07:50.510109Z","shell.execute_reply.started":"2025-08-23T19:07:50.504455Z","shell.execute_reply":"2025-08-23T19:07:50.509483Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def dynamic_thresholding(img, perc=99.5):\n    s = np.percentile(np.abs(img.ravel()), perc)\n    s = np.max([s, 1])\n    img = img.clip(-s, s) / s\n    return img\n\nclass Diffuser:\n    def __init__(self, denoiser, class_guidance, diffusion_steps, perc_thresholding=99.5, batch_size=64):\n        self.denoiser = denoiser\n        self.class_guidance = class_guidance\n        self.diffusion_steps = diffusion_steps\n        self.noise_levels = 1 - np.power(np.arange(0.0001, 0.99, 1 / self.diffusion_steps), 1 / 3)\n        self.noise_levels[-1] = 0.01\n        self.perc_thresholding = perc_thresholding\n        self.batch_size = batch_size\n\n    def predict_x_zero(self, x_t, label, noise_level):\n        num_imgs = len(x_t)\n        label_empty_ohe = np.zeros(shape=label.shape)\n        noise_in = np.array([noise_level] * num_imgs)[:, None, None, None]\n        nn_inputs = [np.vstack([x_t, x_t]),\n                     np.vstack([noise_in, noise_in]),\n                     np.vstack([label, label_empty_ohe])]\n        x0_pred = self.denoiser.predict(nn_inputs, batch_size=self.batch_size, verbose=0)\n        x0_pred_label = x0_pred[:num_imgs]\n        x0_pred_no_label = x0_pred[num_imgs:]\n        x0_pred = self.class_guidance * x0_pred_label + (1 - self.class_guidance) * x0_pred_no_label\n        x0_pred = dynamic_thresholding(x0_pred, perc=self.perc_thresholding)\n        return x0_pred\n\n    def reverse_diffusion(self, seeds, label, show_img=False):\n        new_img = seeds\n        for i in range(len(self.noise_levels) - 1):\n            curr_noise, next_noise = self.noise_levels[i], self.noise_levels[i + 1]\n            x0_pred = self.predict_x_zero(new_img, label, curr_noise)\n            new_img = ((curr_noise - next_noise) * x0_pred + next_noise * new_img) / curr_noise\n            if show_img:\n                plot_images(x0_pred, nrows=int(np.sqrt(len(new_img))), save_name=str(i), size=12)\n                plt.show()\n        return x0_pred\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:07:50.510844Z","iopub.execute_input":"2025-08-23T19:07:50.511027Z","iopub.status.idle":"2025-08-23T19:07:50.525185Z","shell.execute_reply.started":"2025-08-23T19:07:50.511013Z","shell.execute_reply":"2025-08-23T19:07:50.524615Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def batch_generator(model, model_path, train_data, train_label_embeddings, epochs,\n                    batch_size, rand_image, labels, home_dir, diffuser, epoch=0):\n    indices = np.arange(len(train_data))\n    batch = []\n    print(\"Training for {0}\".format(epochs))\n    while epoch < epochs:\n        print(\"saving model:\")\n        model.save(model_path)  # TF SavedModel\n\n        if epoch % 1 == 0:\n            diffuser.denoiser = model\n            imgs = diffuser.reverse_diffusion(rand_image, labels)\n            imgs = decode_latents(imgs, std_latent=std_latent)\n            img_path = os.path.join(home_dir, str(epoch))\n            plot_images(imgs, save_name=img_path, nrows=int(np.sqrt(len(imgs))))\n\n        print(\"new epoch {0}\".format(epoch))\n        np.random.shuffle(indices)\n        for i in indices:\n            batch.append(i)\n            if len(batch) == batch_size:\n                tr_batch = train_data[batch].copy()\n\n                s = np.random.binomial(1, 0.15, size=batch_size).astype(\"bool\")\n                train_label_dropout = train_label_embeddings[batch].copy()\n                train_label_dropout[s] = np.zeros(shape=train_label_embeddings.shape[1])\n\n                noisy_train_data, noise_level_train = add_noise(tr_batch, mu=0, std=1)\n                noise_level_train = noise_level_train[:, None, None, None]\n\n                yield (noisy_train_data, noise_level_train, train_label_dropout), tr_batch\n                batch = []\n        epoch += 1\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:07:50.525894Z","iopub.execute_input":"2025-08-23T19:07:50.526602Z","iopub.status.idle":"2025-08-23T19:07:50.543328Z","shell.execute_reply.started":"2025-08-23T19:07:50.526556Z","shell.execute_reply":"2025-08-23T19:07:50.542717Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 256\ndiffuser = Diffuser(unet, class_guidance=class_guidance, diffusion_steps=100, perc_thresholding=99.75)\n\ntrain_generator = batch_generator(unet,\n                                  model_path,\n                                  latent_train_data,\n                                  train_label_embeddings,\n                                  epochs,\n                                  batch_size,\n                                  rand_image,\n                                  labels,\n                                  home_dir,\n                                  diffuser)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:07:50.544080Z","iopub.execute_input":"2025-08-23T19:07:50.544819Z","iopub.status.idle":"2025-08-23T19:07:50.560348Z","shell.execute_reply.started":"2025-08-23T19:07:50.544794Z","shell.execute_reply":"2025-08-23T19:07:50.559712Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = unet.fit(x=train_generator, epochs=epochs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:07:50.561325Z","iopub.execute_input":"2025-08-23T19:07:50.561557Z","iopub.status.idle":"2025-08-23T19:19:52.445004Z","shell.execute_reply.started":"2025-08-23T19:07:50.561542Z","shell.execute_reply":"2025-08-23T19:19:52.443497Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install git+https://github.com/openai/CLIP.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:19:55.956350Z","iopub.execute_input":"2025-08-23T19:19:55.956921Z","iopub.status.idle":"2025-08-23T19:21:08.012882Z","shell.execute_reply.started":"2025-08-23T19:19:55.956895Z","shell.execute_reply":"2025-08-23T19:21:08.011880Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"unet = keras.models.load_model(\n        \"/kaggle/working/text_to_image/text_to_image.h5\",\n        custom_objects={\"sinusoidal_embedding\": sinusoidal_embedding, \"attention\": attention},\n        compile=False,\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:21:08.014717Z","iopub.execute_input":"2025-08-23T19:21:08.014978Z","iopub.status.idle":"2025-08-23T19:21:11.011222Z","shell.execute_reply.started":"2025-08-23T19:21:08.014954Z","shell.execute_reply":"2025-08-23T19:21:11.010383Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"diffuser = Diffuser(unet,\n                    class_guidance=6,\n                    diffusion_steps=100, perc_thresholding=99.75)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:21:11.012505Z","iopub.execute_input":"2025-08-23T19:21:11.012728Z","iopub.status.idle":"2025-08-23T19:21:11.016613Z","shell.execute_reply.started":"2025-08-23T19:21:11.012711Z","shell.execute_reply":"2025-08-23T19:21:11.015849Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport clip\n# Load the CLIP model and tokenizer  cuda\nmodel, tokenizer = clip.load(\"ViT-B/32\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:21:11.018337Z","iopub.execute_input":"2025-08-23T19:21:11.018514Z","iopub.status.idle":"2025-08-23T19:21:23.014393Z","shell.execute_reply.started":"2025-08-23T19:21:11.018500Z","shell.execute_reply":"2025-08-23T19:21:23.013810Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"text = \"beautiful landscape with river and flowers\"\ntext_tokens = clip.tokenize(text, truncate=False).cuda()\n\nwith torch.no_grad():\n    text_encoding = model.encode_text(text_tokens)\n\ntext_encoding = np.vstack(text_encoding.repeat(4, 1).cpu())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:22:28.064028Z","iopub.execute_input":"2025-08-23T19:22:28.064330Z","iopub.status.idle":"2025-08-23T19:22:28.081156Z","shell.execute_reply.started":"2025-08-23T19:22:28.064308Z","shell.execute_reply":"2025-08-23T19:22:28.080524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"text_encoding.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:22:28.300528Z","iopub.execute_input":"2025-08-23T19:22:28.301137Z","iopub.status.idle":"2025-08-23T19:22:28.305786Z","shell.execute_reply.started":"2025-08-23T19:22:28.301113Z","shell.execute_reply":"2025-08-23T19:22:28.305211Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rand_image = np.random.normal(0, 1, (4, 16, 16, 4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:22:30.192543Z","iopub.execute_input":"2025-08-23T19:22:30.192854Z","iopub.status.idle":"2025-08-23T19:22:30.197081Z","shell.execute_reply.started":"2025-08-23T19:22:30.192831Z","shell.execute_reply":"2025-08-23T19:22:30.196206Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\nimport matplotlib.pyplot as plt\ndiffuser.denoiser = unet\n\nwith torch.no_grad():\n    imgs = diffuser.reverse_diffusion(rand_image, text_encoding)\n    imgs = decode_latents(imgs, std_latent=std_latent)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:22:30.448756Z","iopub.execute_input":"2025-08-23T19:22:30.449029Z","iopub.status.idle":"2025-08-23T19:22:42.269920Z","shell.execute_reply.started":"2025-08-23T19:22:30.449008Z","shell.execute_reply":"2025-08-23T19:22:42.269088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"imgs.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:22:42.271413Z","iopub.execute_input":"2025-08-23T19:22:42.271673Z","iopub.status.idle":"2025-08-23T19:22:42.276734Z","shell.execute_reply.started":"2025-08-23T19:22:42.271649Z","shell.execute_reply":"2025-08-23T19:22:42.276000Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_images(imgs, nrows=2, save_name = text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-23T19:22:42.277603Z","iopub.execute_input":"2025-08-23T19:22:42.277916Z","iopub.status.idle":"2025-08-23T19:22:42.827464Z","shell.execute_reply.started":"2025-08-23T19:22:42.277897Z","shell.execute_reply":"2025-08-23T19:22:42.826520Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}